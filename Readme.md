# Teclado Virtual Controlado con la Mirada ğŸ‘ï¸ğŸ•¹ï¸

Una soluciÃ³n open-source de visiÃ³n por computadora que detecta la direcciÃ³n de la mirada en tiempo real y la traduce en pulsaciones de â€œjoystickâ€ para controlar un teclado virtual. Ideal para devolver independencia y autonomÃ­a a personas con movilidad reducida.

---

## ğŸ” DescripciÃ³n

utiliza un modelo de Computer Vision entrenado con un dataset personalizado para interpretar hacia dÃ³nde mira el usuario (arriba, abajo, izquierda, derecha o centro). A partir de esa informaciÃ³n:

1. **Procesa** cada fotograma de vÃ­deo (webcam o cÃ¡mara integrada).  
2. **Predice** la direcciÃ³n de la mirada en tiempo real.  
3. **Simula** eventos de teclado o movimientos de cursor como si fuesen â€œjoystickâ€ basados en esa direcciÃ³n.  

---

## ğŸš€ CaracterÃ­sticas principales

- DetecciÃ³n de mirada en 6 estados (
    arriba, abajo, izquierda, derecha, centro  y cerrado
).  
- Control de teclado virtual sin necesidad de hardware EEG.  

---

## ğŸ¤ Contribuciones
Â¡Todas las contribuciones son bienvenidas! Si quieres:

- Proponer mejoras al modelo o al dataset.

- AÃ±adir soporte para mÃ¡s gestos o Ã¡ngulos de mirada.

- Integrar con otras aplicaciones o frameworks.

Abre un issue o crea un pull request en GitHub.

## ğŸ“„ Licencia
Este proyecto estÃ¡ bajo la licencia MIT. Consulta el archivo LICENSE para mÃ¡s detalles.

## ğŸ”— Enlaces Ãºtiles
ğŸ“‚ Dataset: https://universe.roboflow.com/alemancilla/eye_direction

ğŸ“‘ Modelo y dataset: en el codigo archivo best.pt


<video width="640" height="360" controls>
  <source src="HACKATHON/demo.mp4" type="video/mp4">
  Tu navegador no soporta la etiqueta de video.
</video>